{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "metadata": {
        "id": "2ViQhsNcoYNQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Byec67OgoatO",
        "outputId": "eb083d55-077c-4a98-85aa-3e6c5ec72d4f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "text = \"Natural language processing (NLP) is a field \"\n",
        "print(sent_tokenize(text))\n",
        "print(word_tokenize(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQyFuFqJHvIR",
        "outputId": "67433d48-36b5-413f-bb7b-c09203875d13"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Natural language processing (NLP) is a field']\n",
            "['Natural', 'language', 'processing', '(', 'NLP', ')', 'is', 'a', 'field']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "para='''I am Tanya. \n",
        "I am majoring in cse. I have done the ece000,ent345,cse101 and mth308 core courses. \n",
        "I am planning to minor in economics and entrepreneurship.\n",
        "My interests include data_science,cybersecurity,biotech,entrepreneurship,economist,software_engineer,mathematician '''"
      ],
      "metadata": {
        "id": "zjQ3eaeGuZG_"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "para='''I am Tanya. \n",
        "I am majoring in cse. I have done the cse101, ece111, mth100, des130 and com101 core courses. \n",
        "I have done the ent416, ent411, ent412 ,ent413 ,ent415 and esc205 electives.'\n",
        "I am planning to minor in economics.\n",
        "My interests include data_science and cybersecurity. '''"
      ],
      "metadata": {
        "id": "aF-BYY0Vhfqt"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "ps = PorterStemmer()\n",
        "sentences=sent_tokenize(para)\n",
        "nouns=[]\n",
        "with open('facts.pl', 'w') as f:\n",
        "  for sentence in sentences:\n",
        "    words = nltk.pos_tag(nltk.word_tokenize(str(sentence)))\n",
        "    print(words)\n",
        "    for word,pos in words:\n",
        "      if(ps.stem(word)==ps.stem('interests')):\n",
        "        for word,pos in words:\n",
        "          if(word!='interests' and pos=='NN'):\n",
        "            print(\"Interest \",word)\n",
        "            rule = \"interest_inp(\"+word+\").\\n\"\n",
        "            f.write(rule)\n",
        "      elif((ps.stem(word)==ps.stem('core')) or (ps.stem(word)==ps.stem('elective'))):\n",
        "        for word,pos in words:\n",
        "          if((ps.stem(word)!=ps.stem('courses')) and (ps.stem(word)!=ps.stem('core')) and (pos=='NN')):\n",
        "            print(\"Core course \",word)\n",
        "            rule = \"done_inp(\"+word+\").\\n\"\n",
        "            f.write(rule)\n",
        "      elif ((ps.stem(word)==ps.stem('major'))):\n",
        "        for word,pos in words:\n",
        "          if(pos=='NN' and (ps.stem(word)!=ps.stem('branch'))):\n",
        "            print(\"Major \",word)\n",
        "            rule = \"branch_inp(\"+word+\").\\n\"\n",
        "            f.write(rule)\n",
        "      elif(ps.stem(word)==ps.stem('minor')):\n",
        "        for word,pos in words:\n",
        "          if( (ps.stem(word)==ps.stem('economics')) and (pos=='NN' or pos=='NNS')):\n",
        "            print(\"minoring in \",word)\n",
        "            rule = \"eco_minor_inp(\"+word+\").\\n\"\n",
        "            f.write(rule)\n",
        "          elif( (ps.stem(word)==ps.stem('entrepreneurship')) and (pos=='NN'or pos=='NNS')):\n",
        "            print(\"minoring in \",word)\n",
        "            rule = \"ent_minor_inp(\"+word+\").\\n\"\n",
        "            f.write(rule)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tG63UlQixGGH",
        "outputId": "7b21ae49-3dbc-4223-e2e2-110ac6d57f39"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('I', 'PRP'), ('am', 'VBP'), ('Tanya', 'NNP'), ('.', '.')]\n",
            "[('I', 'PRP'), ('am', 'VBP'), ('majoring', 'VBG'), ('in', 'IN'), ('cse', 'NN'), ('.', '.')]\n",
            "Major  cse\n",
            "[('I', 'PRP'), ('have', 'VBP'), ('done', 'VBN'), ('the', 'DT'), ('cse101', 'NN'), (',', ','), ('ece111', 'NN'), (',', ','), ('mth100', 'NN'), (',', ','), ('des130', 'NN'), ('and', 'CC'), ('com101', 'NN'), ('core', 'NN'), ('courses', 'NNS'), ('.', '.')]\n",
            "Core course  cse101\n",
            "Core course  ece111\n",
            "Core course  mth100\n",
            "Core course  des130\n",
            "Core course  com101\n",
            "[('I', 'PRP'), ('have', 'VBP'), ('done', 'VBN'), ('the', 'DT'), ('ent416', 'NN'), (',', ','), ('ent411', 'NN'), (',', ','), ('ent412', 'NN'), (',', ','), ('ent413', 'NN'), (',', ','), ('ent415', 'NN'), ('and', 'CC'), ('esc205', 'JJ'), ('electives', 'NNS'), ('.', '.'), (\"'\", \"''\")]\n",
            "Core course  ent416\n",
            "Core course  ent411\n",
            "Core course  ent412\n",
            "Core course  ent413\n",
            "Core course  ent415\n",
            "[('I', 'PRP'), ('am', 'VBP'), ('planning', 'VBG'), ('to', 'TO'), ('minor', 'VB'), ('in', 'IN'), ('economics', 'NNS'), ('.', '.')]\n",
            "minoring in  economics\n",
            "[('My', 'PRP$'), ('interests', 'NNS'), ('include', 'VBP'), ('data_science', 'NN'), ('and', 'CC'), ('cybersecurity', 'NN'), ('.', '.')]\n",
            "Interest  data_science\n",
            "Interest  cybersecurity\n"
          ]
        }
      ]
    }
  ]
}